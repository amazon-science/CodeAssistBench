[
  {
    "number": 133,
    "title": "step与使用的数据量不符",
    "created_at": "2025-03-07T12:41:55Z",
    "closed_at": "2025-03-12T08:13:32Z",
    "commit_id": "451b8cd64c465dd2f3412f17bf1d2a0ce47b8329",
    "labels": [],
    "url": "https://github.com/om-ai-lab/VLM-R1/issues/133",
    "body": "我使用7k数据并调用如下脚本进行训练，step数却有3500，请问要怎么解决\n\n#!/bin/bash\n\n# 设置环境变量（如果需要）\nexport MASTER_ADDR=\"127.0.0.1\"\nexport MASTER_PORT=\"12346\"\nexport RUN_NAME=\"original_reward_4k_4k\"  # 你可以替换这个为实际的RUN_NAME\n\n# 运行命令\ntorchrun --nproc_per_node=\"8\" \\\n    --nnodes=\"1\" \\\n    --node_rank=\"0\" \\\n    --master_addr=\"$MASTER_ADDR\" \\\n    --master_port=\"$MASTER_PORT\" \\\n    src/open_r1/grpo_text.py \\\n    --deepspeed local_scripts/zero3.json \\\n    --output_dir output/$RUN_NAME \\\n    --model_name_or_path /workspace/denglinger/Qwen2.5-VL-3B-Instruct \\\n    --dataset_name /workspace/denglinger/VLM-R1-main/src/open-r1-multimodal/data_config/chartqa.yaml \\\n    --image_root /workspace/denglinger/Dataset/ChartQA_Dataset \\\n    --max_prompt_length 1024 \\\n    --num_generations 8 \\\n    --per_device_train_batch_size 1 \\\n    --gradient_accumulation_steps 2 \\\n    --logging_steps 1 \\\n    --bf16 \\\n    --torch_dtype bfloat16 \\\n    --data_seed 42 \\\n    --report_to wandb \\\n    --gradient_checkpointing false \\\n    --attn_implementation flash_attention_2 \\\n    --num_train_epochs 1 \\\n    --run_name $RUN_NAME \\\n    --save_steps 100 \\\n    --save_only_model true\n",
    "comments_url": "https://api.github.com/repos/om-ai-lab/VLM-R1/issues/133/comments",
    "author": "dle666",
    "comments": [
      {
        "user": "SZhanZ",
        "created_at": "2025-03-07T13:02:42Z",
        "body": "你好，我们的train sampler更新过了，现在要把`--per_device_train_batch_size`设置为`8`，应该就正常了。"
      },
      {
        "user": "dle666",
        "created_at": "2025-03-07T13:07:42Z",
        "body": "已解决，非常感谢\n"
      }
    ],
    "satisfaction_conditions": [
      "An explanation of why the number of training steps doesn't match the expected amount based on the dataset size",
      "A configuration adjustment that aligns the training steps with the actual dataset size",
      "Clear instructions on which parameter needs to be modified to fix the step count issue"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:06:23"
    }
  },
  {
    "number": 83,
    "title": "有关图像分辨率方面的疑问",
    "created_at": "2025-02-27T09:38:53Z",
    "closed_at": "2025-02-28T01:15:34Z",
    "commit_id": "7cd17f489e15b4d42131b1e1a2135172f72be410",
    "labels": [],
    "url": "https://github.com/om-ai-lab/VLM-R1/issues/83",
    "body": "非常漂亮的工作！有个疑问，关于准备自定义数据集的。请问R1训练过程是动态分辨率还是固定分辨率？LLaMA-Factory的SFT训练呢(假设用的是QWen2.5-VL-3B)？",
    "comments_url": "https://api.github.com/repos/om-ai-lab/VLM-R1/issues/83/comments",
    "author": "CaptainEven",
    "comments": [
      {
        "user": "SZhanZ",
        "created_at": "2025-02-27T10:32:29Z",
        "body": "Hello，你好\nR1和SFT都是动态分辨率"
      },
      {
        "user": "CaptainEven",
        "created_at": "2025-02-28T01:15:34Z",
        "body": "好的，感谢！"
      }
    ],
    "satisfaction_conditions": [
      "Clear information about the resolution handling approach in both R1 training and LLaMA-Factory SFT training",
      "Concise and direct answer to technical questions about image resolution in model training"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:06:29"
    }
  },
  {
    "number": 81,
    "title": "About OOM",
    "created_at": "2025-02-27T05:33:56Z",
    "closed_at": "2025-03-31T06:47:14Z",
    "commit_id": "7cd17f489e15b4d42131b1e1a2135172f72be410",
    "labels": [],
    "url": "https://github.com/om-ai-lab/VLM-R1/issues/81",
    "body": "My parameters are as follows: \n    --nproc_per_node=\"6\"\n    --num_generations 4 \n    --per_device_train_batch_size 4 \n    --gradient_accumulation_steps 1 \n\nI used 6 x H20（6 x 96G）, Out of memory error after 4 steps of training.\nThat doesn't seem to fit with the minimum configuration, and what should I do to fix it?",
    "comments_url": "https://api.github.com/repos/om-ai-lab/VLM-R1/issues/81/comments",
    "author": "Lane315",
    "comments": [
      {
        "user": "qizheng-1-1z",
        "created_at": "2025-02-27T05:57:42Z",
        "body": "i got the same problem,sad.."
      },
      {
        "user": "LaFeuilleMorte",
        "created_at": "2025-02-27T06:22:04Z",
        "body": "> My parameters are as follows: --nproc_per_node=\"6\" --num_generations 4 --per_device_train_batch_size 4 --gradient_accumulation_steps 1\n> \n> I used 6 x H20（6 x 96G）, Out of memory error after 4 steps of training. That doesn't seem to fit with the minimum configuration, and what should I do to fix it?\n\nMaybe you can reduce per_device_train_batch_size to 1?"
      },
      {
        "user": "Lane315",
        "created_at": "2025-02-27T06:48:33Z",
        "body": "> > My parameters are as follows: --nproc_per_node=\"6\" --num_generations 4 --per_device_train_batch_size 4 --gradient_accumulation_steps 1\n> > I used 6 x H20（6 x 96G）, Out of memory error after 4 steps of training. That doesn't seem to fit with the minimum configuration, and what should I do to fix it?\n> \n> Maybe you can reduce per_device_train_batch_size to 1?\n\nYou are right. I know it's possible to reduce the batchsize, but this increases the training time. sad.."
      }
    ],
    "satisfaction_conditions": [
      "A solution that reduces memory usage while maintaining reasonable training time",
      "An explanation of why their current configuration is causing OOM errors despite seemingly meeting minimum requirements",
      "Alternative approaches to resolve OOM errors beyond just reducing batch size"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:06:37"
    }
  },
  {
    "number": 5,
    "title": "Still missing gta_subsample.json",
    "created_at": "2025-02-18T13:56:51Z",
    "closed_at": "2025-02-18T17:21:27Z",
    "commit_id": "d12688cb8add22a435ff5f5d317bd24358486b69",
    "labels": [],
    "url": "https://github.com/om-ai-lab/VLM-R1/issues/5",
    "body": "Hi, authors. Thanks for your great work. As the title said, the gta_subsamples.json is still missing in you r provided link in antohr issue.\n\n#2 ",
    "comments_url": "https://api.github.com/repos/om-ai-lab/VLM-R1/issues/5/comments",
    "author": "yueyang130",
    "comments": [
      {
        "user": "SZhanZ",
        "created_at": "2025-02-18T15:14:59Z",
        "body": "Sorry, I uploaded an incorrect zip file. Let me upload it again."
      },
      {
        "user": "SZhanZ",
        "created_at": "2025-02-18T16:28:53Z",
        "body": "The current one should be ok.\n"
      },
      {
        "user": "yueyang130",
        "created_at": "2025-02-18T17:21:27Z",
        "body": "thanks！"
      }
    ],
    "satisfaction_conditions": [
      "Access to the missing gta_subsample.json file",
      "A working download link for the required file",
      "Timely response to the file access request"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:06:51"
    }
  }
]