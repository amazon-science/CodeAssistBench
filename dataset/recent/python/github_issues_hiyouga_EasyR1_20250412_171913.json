[
  {
    "number": 63,
    "title": "AttributeError: 'Tensor' object has no attribute 'full_tensor'",
    "created_at": "2025-03-05T09:26:21Z",
    "closed_at": "2025-03-06T01:01:18Z",
    "commit_id": "5382de88307e9ae6d08a7b5f99e0acc622c62c83",
    "labels": [],
    "url": "https://github.com/hiyouga/EasyR1/issues/63",
    "body": "我用docker file制作镜像，尝试运行，遇到这个报错：\n/EasyR1/verl/workers/rollout/vllm_rollout/dtensor_weight_loaders.py\", line 284, in redistribute_dtensor\n    local_loaded_weights = loaded_weights.full_tensor()\nAttributeError: 'Tensor' object has no attribute 'full_tensor'\n请问这可能是啥原因？看起来是某些依赖的版本不对？",
    "comments_url": "https://api.github.com/repos/hiyouga/EasyR1/issues/63/comments",
    "author": "h7878778h",
    "comments": [
      {
        "user": "hiyouga",
        "created_at": "2025-03-05T09:37:37Z",
        "body": "At least 2 GPU is needed to run EasyR1"
      },
      {
        "user": "h7878778h",
        "created_at": "2025-03-06T01:01:14Z",
        "body": "> At least 2 GPU is needed to run EasyR1\n\nthanks"
      }
    ],
    "satisfaction_conditions": [
      "Information about the minimum hardware requirements to run EasyR1",
      "Explanation of why the 'full_tensor' attribute error occurs",
      "A concise, direct answer that identifies the root cause of the error"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:15:12"
    }
  },
  {
    "number": 28,
    "title": "is_multimodal_model",
    "created_at": "2025-02-25T09:30:38Z",
    "closed_at": "2025-02-25T11:18:20Z",
    "commit_id": "d09ae3a55f40592412a648d265b26ca3ef8bf67f",
    "labels": [],
    "url": "https://github.com/hiyouga/EasyR1/issues/28",
    "body": "Did anybody faced this problem. when I tried to train Qwen2.5-3B-Instruct model, and i get  an error:\n\n **\"Your model does not support multi-modal inputs\".**\n\ntried on 4*A6000 40GB.\n\nMy trainning shell:\n\npython3 -m verl.trainer.main \\\n    config=examples/grpo_example.yaml \\\n    data.train_files=hiyouga/geometry3k@train \\\n    data.val_files=hiyouga/geometry3k@test \\\n    data.max_prompt_length=4096 \\\n    worker.actor.model.model_path=${MODEL_PATH} \\\n    worker.rollout.tensor_parallel_size=1 \\\n    worker.rollout.enable_chunked_prefill=false \\\n    trainer.experiment_name=qwen2_5_vl_3b_geo \\\n    trainer.n_gpus_per_node=4",
    "comments_url": "https://api.github.com/repos/hiyouga/EasyR1/issues/28/comments",
    "author": "RogersSteve",
    "comments": [
      {
        "user": "hiyouga",
        "created_at": "2025-02-25T10:46:27Z",
        "body": "geometry3k is a multimodal dataset, you should use Qwen2.5 VL model to fit this dataset"
      },
      {
        "user": "RogersSteve",
        "created_at": "2025-02-25T11:18:17Z",
        "body": "> geometry3k is a multimodal dataset, you should use Qwen2.5 VL model to fit this dataset\n\nThanks for your reply, it worked!"
      }
    ],
    "satisfaction_conditions": [
      "Identification of the correct model type needed for multimodal datasets",
      "A solution that resolves the 'Your model does not support multi-modal inputs' error",
      "Guidance on model selection appropriate for the geometry3k dataset"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:15:19"
    }
  }
]