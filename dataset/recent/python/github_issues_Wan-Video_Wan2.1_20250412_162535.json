[
  {
    "number": 132,
    "title": "Killed when generated video",
    "created_at": "2025-03-02T05:04:44Z",
    "closed_at": "2025-03-04T09:54:01Z",
    "labels": [],
    "url": "https://github.com/Wan-Video/Wan2.1/issues/132",
    "body": "[2025-03-02 12:01:03,397] INFO: Input image: examples/i2v_input.JPG\n[2025-03-02 12:01:03,542] INFO: Creating WanI2V pipeline.\n[2025-03-02 12:01:54,569] INFO: loading .cache/modelscope/hub/models/Wan-AI/Wan2___1-I2V-14B-480P/models_t5_umt5-xxl-enc-bf16.pth\n[2025-03-02 12:02:05,031] INFO: loading .cache/modelscope/hub/models/Wan-AI/Wan2___1-I2V-14B-480P/Wan2.1_VAE.pth\n[2025-03-02 12:02:05,867] INFO: loading .cache/modelscope/hub/models/Wan-AI/Wan2___1-I2V-14B-480P/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\n[2025-03-02 12:02:11,709] INFO: Creating WanModel from .cache/modelscope/hub/models/Wan-AI/Wan2___1-I2V-14B-480P\n[2025-03-02 12:02:35,384] INFO: Generating video ...\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [45:42<00:00, 68.55s/it]\nKilled",
    "comments_url": "https://api.github.com/repos/Wan-Video/Wan2.1/issues/132/comments",
    "author": "DorothyDoro",
    "comments": [
      {
        "user": "wxwwt",
        "created_at": "2025-03-02T06:26:00Z",
        "body": "I also have this problem\n\n\n(myenv) dministrator@DESKTOP-C3RIDG2:/opt/project/Wan2.1$ python generate.py  --task t2v-1.3B --size 832*480 --ckpt_dir ./Wan2.1-T2V-1.3B --prompt \"Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.\"\n[2025-03-02 13:59:35,781] INFO: offload_model is not specified, set to True.\n[2025-03-02 13:59:35,781] INFO: Generation job args: Namespace(task='t2v-1.3B', size='832*480', frame_num=81, ckpt_dir='./Wan2.1-T2V-1.3B', offload_model=True, ulysses_size=1, ring_size=1, t5_fsdp=False, t5_cpu=False, dit_fsdp=False, save_file=None, prompt='Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.', use_prompt_extend=False, prompt_extend_method='local_qwen', prompt_extend_model=None, prompt_extend_target_lang='ch', base_seed=8478258736304712572, image=None, sample_solver='unipc', sample_steps=50, sample_shift=5.0, sample_guide_scale=5.0)\n[2025-03-02 13:59:35,781] INFO: Generation model config: {'__name__': 'Config: Wan T2V 1.3B', 't5_model': 'umt5_xxl', 't5_dtype': torch.bfloat16, 'text_len': 512, 'param_dtype': torch.bfloat16, 'num_train_timesteps': 1000, 'sample_fps': 16, 'sample_neg_prompt': '\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28 \u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70', 't5_checkpoint': 'models_t5_umt5-xxl-enc-bf16.pth', 't5_tokenizer': 'google/umt5-xxl', 'vae_checkpoint': 'Wan2.1_VAE.pth', 'vae_stride': (4, 8, 8), 'patch_size': (1, 2, 2), 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'num_heads': 12, 'num_layers': 30, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06}\n[2025-03-02 13:59:35,781] INFO: Input prompt: Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.\n[2025-03-02 13:59:35,781] INFO: Creating WanT2V pipeline.\nKilled"
      },
      {
        "user": "FurkanGozukara",
        "created_at": "2025-03-02T06:29:22Z",
        "body": "Killed is out of ram\n\nIncrease virtual ram "
      },
      {
        "user": "wxwwt",
        "created_at": "2025-03-02T08:08:50Z",
        "body": "> Killed is out of ram\n> \n> Increase virtual ram\n\nthx  it`s work~"
      }
    ],
    "satisfaction_conditions": [
      "An explanation of why the video generation process is being killed",
      "A solution to prevent the video generation process from being killed",
      "Identification of resource constraints causing the process termination"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-14 01:12:25"
    }
  },
  {
    "number": 131,
    "title": "WSL2 Ubuntu: cache_video failed, error: result type Float can't be cast to the desired output type Byte",
    "created_at": "2025-03-01T17:20:49Z",
    "closed_at": "2025-03-01T20:22:42Z",
    "labels": [],
    "url": "https://github.com/Wan-Video/Wan2.1/issues/131",
    "body": "\n\n\npython generate.py  --task t2v-1.3B --size 480*832 --ckpt_dir ./Wan2.1-T2V-1.3B --prompt \"a metallic skeleton robot on a cooking show, preparing a recipe with a whole chicken\" --save_file ./output.mp4\n\n\n[2025-03-01 14:01:36,940] INFO: offload_model is not specified, set to True.\n[2025-03-01 14:01:36,940] INFO: Generation job args: Namespace(task='t2v-1.3B', size='480*832', frame_num=81, ckpt_dir='./Wan2.1-T2V-1.3B', offload_model=True, ulysses_size=1, ring_size=1, t5_fsdp=False, t5_cpu=False, dit_fsdp=False, save_file='./output.mp4', prompt='a metallic skeleton robot on a cooking show, preparing a recipe with a whole chicken', use_prompt_extend=False, prompt_extend_method='local_qwen', prompt_extend_model=None, prompt_extend_target_lang='ch', base_seed=4277550218863685172, image=None, sample_solver='unipc', sample_steps=50, sample_shift=5.0, sample_guide_scale=5.0)\n[2025-03-01 14:01:36,940] INFO: Generation model config: {'__name__': 'Config: Wan T2V 1.3B', 't5_model': 'umt5_xxl', 't5_dtype': torch.bfloat16, 'text_len': 512, 'param_dtype': torch.bfloat16, 'num_train_timesteps': 1000, 'sample_fps': 16, 'sample_neg_prompt': '\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28 \u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70', 't5_checkpoint': 'models_t5_umt5-xxl-enc-bf16.pth', 't5_tokenizer': 'google/umt5-xxl', 'vae_checkpoint': 'Wan2.1_VAE.pth', 'vae_stride': (4, 8, 8), 'patch_size': (1, 2, 2), 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'num_heads': 12, 'num_layers': 30, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06}\n[2025-03-01 14:01:36,940] INFO: Input prompt: a metallic skeleton robot on a cooking show, preparing a recipe with a whole chicken\n[2025-03-01 14:01:36,940] INFO: Creating WanT2V pipeline.\n[2025-03-01 14:02:33,960] INFO: loading ./Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n[2025-03-01 14:03:39,030] INFO: loading ./Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\n[2025-03-01 14:03:41,640] INFO: Creating WanModel from ./Wan2.1-T2V-1.3B\n[2025-03-01 14:07:17,091] INFO: Generating video ...\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [08:27<00:00, 10.16s/it]\n[2025-03-01 14:16:14,586] INFO: Saving generated video to ./output.mp4\ncache_video failed, error: result type Float can't be cast to the desired output type Byte\n[2025-03-01 14:16:15,400] INFO: Finished.",
    "comments_url": "https://api.github.com/repos/Wan-Video/Wan2.1/issues/131/comments",
    "author": "egaralmeida",
    "comments": [
      {
        "user": "egaralmeida",
        "created_at": "2025-03-01T20:22:42Z",
        "body": "Fixed by installing imageio-ffmpeg, which is in the requirements. Not sure why it didn't install for me along many other requirements."
      },
      {
        "user": "garysdevil",
        "created_at": "2025-03-02T03:21:53Z",
        "body": "```log\nheckpoint': 'Wan2.1_VAE.pth', 'vae_stride': (4, 8, 8), 'patch_size': (1, 2, 2), 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'num_heads': 12, 'num_layers': 30, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06}\n[2025-03-02 10:33:59,629] INFO: Input prompt: Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.\n[2025-03-02 10:33:59,629] INFO: Creating WanT2V pipeline.\n[2025-03-02 10:34:36,622] INFO: loading ./Wan2.1-T2V-1.3B\\models_t5_umt5-xxl-enc-bf16.pth\n[2025-03-02 10:34:41,096] INFO: loading ./Wan2.1-T2V-1.3B\\Wan2.1_VAE.pth\n[2025-03-02 10:34:41,508] INFO: Creating WanModel from ./Wan2.1-T2V-1.3B\n[2025-03-02 10:34:43,656] INFO: Generating video ...\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [15:22<00:00, 18.45s/it]\n[2025-03-02 10:52:29,068] INFO: Saving generated video to 1.pm4\ncache_video failed, error: result type Float can't be cast to the desired output type Byte\n[2025-03-02 10:52:29,291] INFO: Finished.\n(wan2.1) PS D:\\Dev\\Wan2.1> pip install imageio-ffmpeg                                                                         \nRequirement already satisfied: imageio-ffmpeg in c:\\users\\gary\\.conda\\envs\\wan2.1\\lib\\site-packages (0.6.0)                   \n(wan2.1) PS D:\\Dev\\Wan2.1> \n```"
      },
      {
        "user": "dieptran2500",
        "created_at": "2025-03-02T17:38:19Z",
        "body": "i have same problem , any one know how to fix?"
      },
      {
        "user": "lxm065",
        "created_at": "2025-03-04T02:15:27Z",
        "body": "i have the same problem , and i install imageio-ffmpeg\n\nError opening output files: Invalid argument\n\n\n[2025-03-04 10:03:31,847] INFO: Saving generated video to t2v-1.3B_832*480_1_1_Two_anthropomorphic_cats_in_comfy_boxing_gear_and__20250304_100331.mp4\n[out#0/mp4 @ 00000128ae1f02c0] Error opening output D:\\ai\\Wan2.1\\t2v-1.3B_832*480_1_1_Two_anthropomorphic_cats_in_comfy_boxing_gear_and__20250304_100331.mp4: Invalid argument\nError opening output file D:\\ai\\Wan2.1\\t2v-1.3B_832*480_1_1_Two_anthropomorphic_cats_in_comfy_boxing_gear_and__20250304_100331.mp4.\nError opening output files: Invalid argument\ncache_video failed, error: result type Float can't be cast to the desired output type Byte\n[2025-03-04 10:03:32,273] INFO: Finished."
      },
      {
        "user": "garysdevil",
        "created_at": "2025-03-13T14:03:56Z",
        "body": "> ```\n> heckpoint': 'Wan2.1_VAE.pth', 'vae_stride': (4, 8, 8), 'patch_size': (1, 2, 2), 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'num_heads': 12, 'num_layers': 30, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06}\n> [2025-03-02 10:33:59,629] INFO: Input prompt: Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage.\n> [2025-03-02 10:33:59,629] INFO: Creating WanT2V pipeline.\n> [2025-03-02 10:34:36,622] INFO: loading ./Wan2.1-T2V-1.3B\\models_t5_umt5-xxl-enc-bf16.pth\n> [2025-03-02 10:34:41,096] INFO: loading ./Wan2.1-T2V-1.3B\\Wan2.1_VAE.pth\n> [2025-03-02 10:34:41,508] INFO: Creating WanModel from ./Wan2.1-T2V-1.3B\n> [2025-03-02 10:34:43,656] INFO: Generating video ...\n> 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [15:22<00:00, 18.45s/it]\n> [2025-03-02 10:52:29,068] INFO: Saving generated video to 1.pm4\n> cache_video failed, error: result type Float can't be cast to the desired output type Byte\n> [2025-03-02 10:52:29,291] INFO: Finished.\n> (wan2.1) PS D:\\Dev\\Wan2.1> pip install imageio-ffmpeg                                                                         \n> Requirement already satisfied: imageio-ffmpeg in c:\\users\\gary\\.conda\\envs\\wan2.1\\lib\\site-packages (0.6.0)                   \n> (wan2.1) PS D:\\Dev\\Wan2.1> \n> ```\n\nI resolve this question by setting an absolute path `--save_file \"D:\\Dev\\Wan2.1\\2.1.mp4\" `"
      }
    ],
    "satisfaction_conditions": [
      "A solution that resolves the 'cache_video failed, error: result type Float can't be cast to the desired output type Byte' error",
      "A way to successfully save the generated video output to a file",
      "A solution that addresses dependency or configuration issues in the video generation pipeline",
      "A workaround for file path handling issues"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-14 01:12:35"
    }
  },
  {
    "number": 50,
    "title": "\u8fd0\u884c1.3B\u7684gradio\u4f1a\u81ea\u52a8\u4e0b\u8f7d14B\u7684\u6a21\u578b",
    "created_at": "2025-02-26T09:25:40Z",
    "closed_at": "2025-03-04T09:47:36Z",
    "labels": [],
    "url": "https://github.com/Wan-Video/Wan2.1/issues/50",
    "body": "\u8fd0\u884c\u65f6\u4f1a\u4e0b\u8f7d\u4e00\u4e2amodels--Qwen--Qwen2.5-14B-Instruct\u6587\u4ef6\u5939\uff0c28G\u5927\u5c0f",
    "comments_url": "https://api.github.com/repos/Wan-Video/Wan2.1/issues/50/comments",
    "author": "jasonlbx13",
    "comments": [
      {
        "user": "Memoriaaa",
        "created_at": "2025-02-26T09:40:03Z",
        "body": "gradio\u7684demo\u9ed8\u8ba4\u5f00\u4e86\u63d0\u793a\u8bcd\u589e\u5f3a\uff0c\u4f1a\u8c03\u7528Qwen2.5\uff0c\u4f60\u53ef\u4ee5\u6539\u4e0b\u4ee3\u7801\u5173\u4e86\n\n\u53c2\u8003\uff1a\n```python\n# Copyright 2024-2025 The Alibaba Wan Team Authors. All rights reserved.\nimport argparse\nimport os.path as osp\nimport sys\nimport warnings\n\nimport gradio as gr\n\nwarnings.filterwarnings('ignore')\n\n# Model\nsys.path.insert(0, '/'.join(osp.realpath(__file__).split('/')[:-2]))\nimport wan\nfrom wan.configs import WAN_CONFIGS\nfrom wan.utils.prompt_extend import DashScopePromptExpander, QwenPromptExpander\nfrom wan.utils.utils import cache_video\n\n# Global Var\nprompt_expander = None\nwan_t2v = None\n\n\n# Button Func\ndef prompt_enc(prompt, tar_lang):\n    return prompt\n    # global prompt_expander\n    # prompt_output = prompt_expander(prompt, tar_lang=tar_lang.lower())\n    # if prompt_output.status == False:\n    #     return prompt\n    # else:\n    #     return prompt_output.prompt\n\n\ndef t2v_generation(txt2vid_prompt, resolution, sd_steps, guide_scale,\n                   shift_scale, seed, n_prompt):\n    global wan_t2v\n    # print(f\"{txt2vid_prompt},{resolution},{sd_steps},{guide_scale},{shift_scale},{seed},{n_prompt}\")\n\n    W = int(resolution.split(\"*\")[0])\n    H = int(resolution.split(\"*\")[1])\n    video = wan_t2v.generate(\n        txt2vid_prompt,\n        size=(W, H),\n        shift=shift_scale,\n        sampling_steps=sd_steps,\n        guide_scale=guide_scale,\n        n_prompt=n_prompt,\n        seed=seed,\n        offload_model=False)\n\n    cache_video(\n        tensor=video[None],\n        save_file=\"example.mp4\",\n        fps=16,\n        nrow=1,\n        normalize=True,\n        value_range=(-1, 1))\n\n    return \"example.mp4\"\n\n\n# Interface\ndef gradio_interface():\n    with gr.Blocks() as demo:\n        gr.Markdown(\"\"\"\n                    <div style=\"text-align: center; font-size: 32px; font-weight: bold; margin-bottom: 20px;\">\n                        Wan2.1 (T2V-1.3B)\n                    </div>\n                    <div style=\"text-align: center; font-size: 16px; font-weight: normal; margin-bottom: 20px;\">\n                        Wan: Open and Advanced Large-Scale Video Generative Models.\n                    </div>\n                    \"\"\")\n\n        with gr.Row():\n            with gr.Column():\n                txt2vid_prompt = gr.Textbox(\n                    label=\"Prompt\",\n                    placeholder=\"Describe the video you want to generate\",\n                )\n                tar_lang = gr.Radio(\n                    choices=[\"CH\", \"EN\"],\n                    label=\"Target language of prompt enhance\",\n                    value=\"CH\")\n                run_p_button = gr.Button(value=\"Prompt Enhance\")\n\n                with gr.Accordion(\"Advanced Options\", open=True):\n                    resolution = gr.Dropdown(\n                        label='Resolution(Width*Height)',\n                        choices=[\n                            '480*832',\n                            '832*480',\n                            '624*624',\n                            '704*544',\n                            '544*704',\n                        ],\n                        value='480*832')\n\n                    with gr.Row():\n                        sd_steps = gr.Slider(\n                            label=\"Diffusion steps\",\n                            minimum=1,\n                            maximum=1000,\n                            value=50,\n                            step=1)\n                        guide_scale = gr.Slider(\n                            label=\"Guide scale\",\n                            minimum=0,\n                            maximum=20,\n                            value=6.0,\n                            step=1)\n                    with gr.Row():\n                        shift_scale = gr.Slider(\n                            label=\"Shift scale\",\n                            minimum=0,\n                            maximum=20,\n                            value=8.0,\n                            step=1)\n                        seed = gr.Slider(\n                            label=\"Seed\",\n                            minimum=-1,\n                            maximum=2147483647,\n                            step=1,\n                            value=-1)\n                    n_prompt = gr.Textbox(\n                        label=\"Negative Prompt\",\n                        placeholder=\"Describe the negative prompt you want to add\"\n                    )\n\n                run_t2v_button = gr.Button(\"Generate Video\")\n\n            with gr.Column():\n                result_gallery = gr.Video(\n                    label='Generated Video', interactive=False, height=600)\n\n        run_p_button.click(\n            fn=prompt_enc,\n            inputs=[txt2vid_prompt, tar_lang],\n            outputs=[txt2vid_prompt])\n\n        run_t2v_button.click(\n            fn=t2v_generation,\n            inputs=[\n                txt2vid_prompt, resolution, sd_steps, guide_scale, shift_scale,\n                seed, n_prompt\n            ],\n            outputs=[result_gallery],\n        )\n\n    return demo\n\n\n# Main\ndef _parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Generate a video from a text prompt or image using Gradio\")\n    parser.add_argument(\n        \"--ckpt_dir\",\n        type=str,\n        default=\"cache\",\n        help=\"The path to the checkpoint directory.\")\n    parser.add_argument(\n        \"--prompt_extend_method\",\n        type=str,\n        default=\"local_qwen\",\n        choices=[\"dashscope\", \"local_qwen\", \"None\"],\n        help=\"The prompt extend method to use.\")\n    parser.add_argument(\n        \"--prompt_extend_model\",\n        type=str,\n        default=None,\n        help=\"The prompt extend model to use.\")\n\n    args = parser.parse_args()\n\n    return args\n\n\nif __name__ == '__main__':\n    args = _parse_args()\n\n    # print(\"Step1: Init prompt_expander...\", end='', flush=True)\n    # if args.prompt_extend_method == \"dashscope\":\n    #     prompt_expander = DashScopePromptExpander(\n    #         model_name=args.prompt_extend_model, is_vl=False)\n    # elif args.prompt_extend_method == \"local_qwen\":\n    #     prompt_expander = QwenPromptExpander(\n    #         model_name=args.prompt_extend_model, is_vl=False, device=0)\n    # else:\n    #     raise NotImplementedError(\n    #         f\"Unsupport prompt_extend_method: {args.prompt_extend_method}\")\n    # print(\"done\", flush=True)\n\n    print(\"Step2: Init 1.3B t2v model...\", end='', flush=True)\n    cfg = WAN_CONFIGS['t2v-1.3B']\n    wan_t2v = wan.WanT2V(\n        config=cfg,\n        checkpoint_dir=args.ckpt_dir,\n        device_id=0,\n        rank=0,\n        t5_fsdp=False,\n        dit_fsdp=False,\n        use_usp=False,\n    )\n    print(\"done\", flush=True)\n\n    demo = gradio_interface()\n    demo.launch(server_name=\"0.0.0.0\", share=False, server_port=8904)\n```"
      },
      {
        "user": "jasonlbx13",
        "created_at": "2025-02-26T09:42:36Z",
        "body": "\u611f\u8c22\u60a8\u7684\u89e3\u7b54\uff01\n\n"
      },
      {
        "user": "fallbernana123456",
        "created_at": "2025-02-26T09:48:38Z",
        "body": "> \u611f\u8c22\u60a8\u7684\u89e3\u7b54\uff01\n\n\u4f60\u5728\u963f\u91cc\u4e91\u4e0a\u7533\u8bf7\u4e00\u4e2a api-key\uff0c\u518d\u4f7f\u7528--prompt_extend_method 'dashscope'\u53c2\u6570\u5c31\u53ef\u4ee5\u4f7f\u7528\u4e86\n"
      }
    ],
    "satisfaction_conditions": [
      "A solution that prevents the automatic download of the large 14B Qwen model",
      "Code modification guidance to disable the prompt enhancement feature",
      "Understanding of why the large model was being downloaded"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-14 01:13:08"
    }
  }
]