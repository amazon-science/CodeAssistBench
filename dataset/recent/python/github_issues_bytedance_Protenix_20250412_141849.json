[
  {
    "number": 35,
    "title": "Error when only predicting ligand",
    "created_at": "2024-12-08T15:34:57Z",
    "closed_at": "2024-12-17T12:52:40Z",
    "commit_id": "a7803a8f137d256285b5b83f3338a0ee17f2e91d",
    "labels": [],
    "url": "https://github.com/bytedance/Protenix/issues/35",
    "body": "Hi! I wanna only predict the ligand structure, but proteinix raised errors:\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/workspace/runner/inference.py\", line 213, in main\r\n    runner.dumper.dump(\r\n  File \"/workspace/runner/dumper.py\", line 74, in dump\r\n    self.dump_predictions(\r\n  File \"/workspace/runner/dumper.py\", line 107, in dump_predictions\r\n    self._save_structure(\r\n  File \"/workspace/runner/dumper.py\", line 135, in _save_structure\r\n    save_structure_cif(\r\n  File \"/workspace/protenix/data/utils.py\", line 181, in save_structure_cif\r\n    save_atoms_to_cif(\r\n  File \"/workspace/protenix/data/utils.py\", line 154, in save_atoms_to_cif\r\n    cifwriter.save_to_cif(\r\n  File \"/workspace/protenix/data/utils.py\", line 288, in save_to_cif\r\n    block_dict.update(self._get_entity_poly_and_entity_poly_seq_block())\r\n  File \"/workspace/protenix/data/utils.py\", line 260, in _get_entity_poly_and_entity_poly_seq_block\r\n    \"entity_poly\": pdbx.CIFCategory(entity_poly),\r\n  File \"/opt/conda/lib/python3.10/site-packages/biotite/structure/io/pdbx/cif.py\", line 327, in __init__\r\n    columns = {\r\n  File \"/opt/conda/lib/python3.10/site-packages/biotite/structure/io/pdbx/cif.py\", line 328, in <dictcomp>\r\n    key: CIFColumn(col) if not isinstance(col, CIFColumn) else col\r\n  File \"/opt/conda/lib/python3.10/site-packages/biotite/structure/io/pdbx/cif.py\", line 138, in __init__\r\n    data = CIFData(data, str)\r\n  File \"/opt/conda/lib/python3.10/site-packages/biotite/structure/io/pdbx/cif.py\", line 66, in __init__\r\n    self._array = _arrayfy(array)\r\n  File \"/opt/conda/lib/python3.10/site-packages/biotite/structure/io/pdbx/cif.py\", line 1061, in _arrayfy\r\n    raise ValueError(\"Array must contain at least one element\")\r\nValueError: Array must contain at least one element\r\n```\r\n\r\nThe json file is:\r\n```\r\n[\r\n    {\r\n        \"sequences\": [\r\n            {\r\n                \"ligand\": {\r\n                    \"ligand\": \"COc1cc(OC)ccc1/C=C/N(C(=O)C)C\",\r\n                    \"count\": 1\r\n                }\r\n            }\r\n        ],\r\n        \"modelSeeds\": [],\r\n        \"assembly_id\": \"1\",\r\n        \"name\": \"LIG_1\"\r\n    }\r\n]\r\n\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/bytedance/Protenix/issues/35/comments",
    "author": "v-shaoningli",
    "comments": [
      {
        "user": "cloverzizi",
        "created_at": "2024-12-12T03:05:45Z",
        "body": "Hi Shaoning, \r\n\r\nThis issue has been resolved in the recent code update. The task results without polymer can now be saved normally. \r\nThank you for the feedback :D\r\n"
      },
      {
        "user": "v-shaoningli",
        "created_at": "2024-12-12T08:12:44Z",
        "body": "Thanks for the update!"
      }
    ],
    "satisfaction_conditions": [
      "A solution that allows predicting only ligand structures without errors",
      "Proper handling of cases where only ligand data is provided in the input JSON",
      "Successful saving/output of prediction results for ligand-only tasks"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-14 01:14:41"
    },
    "dockerfile": "FROM ai4s-cn-beijing.cr.volces.com/pytorch-mirror/pytorch:2.3.1-cuda12.1-cudnn8-devel\n\n# Set environment variables\nENV DEBIAN_FRONTEND=noninteractive\nENV TZ=Asia/Shanghai\n\n# Install system dependencies\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n    wget \\\n    g++ \\\n    gcc \\\n    libc6-dev \\\n    make zlib1g zlib1g-dev \\\n    git git-lfs expect zsh vim wget curl unzip zip cmake cmake-curses-gui libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev \\\n    libxrender1 libxext6 iproute2 \\\n    postgresql \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install HHsuite\nRUN DEBIAN_FRONTEND=noninteractive apt-get update && \\\n    apt-get install --no-install-recommends -y hmmer cmake cmake-curses-gui && \\\n    git clone --branch v3.3.0 https://github.com/soedinglab/hh-suite.git /tmp/hh-suite && \\\n    mkdir /tmp/hh-suite/build && \\\n    cd /tmp/hh-suite/build && \\\n    cmake -DCMAKE_INSTALL_PREFIX=/opt/hhsuite .. && \\\n    make -j 32 && make install && \\\n    ln -s /opt/hhsuite/bin/* /usr/bin && \\\n    cd - && \\\n    rm -rf /tmp/hh-suite && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nRUN pip3 --no-cache-dir install \\\n    scipy \\\n    ml_collections \\\n    tqdm \\\n    pandas \\\n    dm-tree==0.1.6 \\\n    rdkit==\"2023.03.01\" \\\n    biopython==1.83 \\\n    modelcif==0.7 \\\n    biotite==1.0.1 \\\n    gemmi==0.6.5 \\\n    pdbeccdutils==0.8.5 \\\n    scikit-learn==1.2.2 \\\n    scikit-learn-extra \\\n    deepspeed==0.14.4 \\\n    protobuf==3.20.2 \\\n    tos icecream ipdb wandb numpy==1.26.3 matplotlib==3.9.2 ipywidgets py3Dmol\n\n# For H20 compatibility\nRUN pip3 install --no-cache-dir nvidia-cublas-cu12==12.4.5.8 --no-deps\n\n# Clone CUTLASS for DeepSpeed DS4Sci_EvoformerAttention kernel\nRUN git clone -b v3.5.1 https://github.com/NVIDIA/cutlass.git /opt/cutlass\nENV CUTLASS_PATH=/opt/cutlass\n\n# Clone the repository and checkout the specific commit\nWORKDIR /workspace\nRUN git clone https://github.com/bytedance/Protenix.git && \\\n    cd Protenix && \\\n    git checkout a7803a8f137d256285b5b83f3338a0ee17f2e91d\n\n# Install the package in development mode\nWORKDIR /workspace/Protenix\nRUN pip install -e .\n\n# Create data directories that might be needed for inference\nRUN mkdir -p /af3-dev/release_data /af3-dev/release_model\n\n# Add information about downloading model and data files\nRUN echo \"To download model files run:\" > /workspace/README_FIRST.txt && \\\n    echo \"wget -P /af3-dev/release_model/ https://af3-dev.tos-cn-beijing.volces.com/release_model/model_v1.pt\" >> /workspace/README_FIRST.txt && \\\n    echo \"\" >> /workspace/README_FIRST.txt && \\\n    echo \"To download minimal data files needed for inference:\" >> /workspace/README_FIRST.txt && \\\n    echo \"wget -P /af3-dev/release_data/ https://af3-dev.tos-cn-beijing.volces.com/release_data/components.v20240608.cif\" >> /workspace/README_FIRST.txt && \\\n    echo \"wget -P /af3-dev/release_data/ https://af3-dev.tos-cn-beijing.volces.com/release_data/components.v20240608.cif.rdkit_mol.pkl\" >> /workspace/README_FIRST.txt\n\n# Set the working directory\nWORKDIR /workspace"
  }
]