[
  {
    "number": 13,
    "title": "Simple lock-free framebuffer read & write",
    "created_at": "2024-12-11T03:49:13Z",
    "closed_at": "2024-12-14T15:28:17Z",
    "commit_id": "91b0ee8d69d522a4c5e3868ea3b493c41c66618b",
    "labels": [],
    "url": "https://github.com/xuwd1/wemeet-wayland-screenshare/pull/13",
    "body": "不太清楚 README 中所述功率是如何测得的，因此我并未测试实际的性能提升。\r\n\r\n~无锁的双缓存区应该会带来一些提升？~ 我很乐意补充我本地的性能测试结果，如果你可以告诉我如何评估性能的话。\r\n\r\n---\r\n\r\n此外，我并未仔细检查上下文的注释是否清理/修改妥当，如有不妥，敬请指正。",
    "comments_url": "https://api.github.com/repos/xuwd1/wemeet-wayland-screenshare/issues/13/comments",
    "author": "Coekjan",
    "comments": [
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T07:22:24Z",
        "body": "谢谢你的工作！不过，我认为现在的改动还存在一些问题. 我想首先说明一下为何现在的设计中采用了锁：\r\n- 如你所见，我们的代码中framebuffer的参数是跟随pw的参数变化的\r\n- 在整个从payload写入，到hook读出的过程中，从始至终我们只利用fb中的一块内存作为中转\r\n- fb的参数更新可能会使得fb的内存发生重分配. 更具体地，导致重分配的参数更新主要是pw报告的分辨率发生了变化，有两种主要情形：a. fb的初始参数和开始录制后的实际参数不一致，比如用户使用的是一块2160p屏幕. b. 用户录制的是一个窗口，录制开始后用户改变了窗口的形状\r\n- 因此，在存在这种重分配的情况下，我们必须要设法保证，hook在读取fb时，fb的内存块**不会被重分配**. 否则我们一定会遇到segfault.\r\n\r\n正是基于如上的原因，我最后就采用了加锁的方案. 我可以理解本PR的改动中尝试将锁换为具有一致性保证的原子变量的动机，并且双缓冲的确也拉长了依赖距离，但是我认为现在的设计的一个显著问题是其无法保证双缓冲不存在**翻转**. 我们设想一个场景：\r\n\r\n1. hook开始读fb A，但由于某种原因它读的比较慢，这个过程一直到最后都没能结束\r\n2. payload写完了另一块fb B\r\n3. payload又打算开始写fb A，并且用户恰好最大化了窗口\r\n4. fb A改变参数，程序崩溃\r\n\r\n因此，我认为要取消锁，仅靠改为原子变量是不够的. 我们真正需要的其实是改变这套依赖于重分配的逻辑，或者在尽量避免重分配的同时围绕重分配实现一套安全逻辑. \r\n\r\n最后还是谢谢你的工作，但我认为我们目前的确需要更多努力才能将锁取消.\r\n\r\n最后，关于功耗监测的方法，windows上我主要使用hwinfo64观察功耗，而linux上我用的主要是amdgpu_top. intel平台上应当也有相似的工具（我记得有一个依赖于内核模块的，非常详细的工具，甚至能观察一些hw counter，但我忘记叫什么了.）"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T08:25:21Z",
        "body": "我还想额外补充一点想法：\r\n1. 我想也许我们可以实现某种“huge buffer”. 比如，我们让这个huge buffer足够的大（say, like maybe 8192x8192），这样应该就能使得绝大多数（或者可以说所有）情况下所需要的buffer size都比这个huge buffer小，那么我们就可以保证至少我们始终都在安全的地址空间里. 然后，我们认为所有超出这个buffer size的都是非法情况，那么我们就永远都不需要重分配了. 不过这样也是个很糟糕的方案，光是这个huge buffer我们就需要消耗我们256M的内存. 不过感觉这个方案也可以进一步细化，比如我们先借助XRR看一下用户的显示器分辨率（代码中已经有这种功能），然后根据这个分辨率决定一个“更大，但不太大 (like 1.5 times of the largest screen size, or simply the whole X framebuffer size)”的huge buffer size.\r\n2. 或者我们可以实现一种\"multi-buffer pyramids\"，也就是说我们事先准备一系列小的，不同尺寸的buffer，在参数发生变化时，我们只在这些buffer的范围内选择合适的buffer. 那么即使参数发生变化，我们只需要调整指针指向的实际buffer."
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T08:31:05Z",
        "body": "感谢你的指正。针对“避免重分配”的问题，是否可以考虑仅向 kernel 申请 huge buffer 那么大的虚拟内存空间，真正用到时，kernel 理应会自动（按页/按大页）分配物理内存？"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T08:34:23Z",
        "body": "@Coekjan 感觉这个应该就是basically how VM works. 但是我感觉我们应该至少需要首先对这块buffer全部填0，那么最后还是需要消耗这么多内存. 不过刚才想了下感觉根据屏幕尺寸选择尺寸应该是个比较合理的方案. （毕竟，compositor本身也是要消耗这么多内存的）"
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T08:36:59Z",
        "body": "> 但是我感觉我们应该至少需要首先对这块buffer全部填0，那么最后还是需要消耗这么多内存.\r\n\r\n不可以另外维护“长度”么，这样子 reader 和 writer 在 `data_size` 不变化时只访问“长度”内的区域，当需要访问“长度”外的区域时，再进行初始化（填 0）。"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T08:39:46Z",
        "body": "@Coekjan 啊，这也就是说在参数更新时如果需要再去填0，那我觉得的确是个还不错的主意. 而且无论如何感觉最多256M的消耗应该也还算是一个可以接受的范围.😉"
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T09:33:34Z",
        "body": "> 但是我感觉我们应该至少需要首先对这块buffer全部填0\r\n\r\n填 0 真的是必要的么（主分支上的代码似乎也没有将 buffer 初始化为 0），我现在尝试了一下，似乎不填 0 也不会出大问题？reader 尽管在一开始读到了未初始化的数据，但由于 writer 产生数据的速度足够快，所以用户大概不会感知到这个“不可预知”的 frame。"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T09:47:28Z",
        "body": "@Coekjan 刚才看了一下，是我记错了，我们目前是对ximage填0的：\r\n```\r\n  CvMat ximage_cvmat;\r\n  OpencvDLFCNSingleton::cvInitMatHeader(\r\n    &ximage_cvmat, ximage_height, ximage_width,\r\n    CV_8UC4, image.data, ximage_bytes_per_line\r\n  );\r\n  OpencvDLFCNSingleton::cvSetZero(&ximage_cvmat);\r\n```\r\n\r\n这样的话你说的是对的，我们的确可以不去管buffer的内容.😃"
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T10:01:40Z",
        "body": "请查收最新 push 的版本：\r\n1. 使用了 huge buffer 的思路，不需要初始化值，因此仅占据虚拟内存，并不会导致物理内存开销变大；\r\n2. 完全移除了对应的 mutex。"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T10:06:00Z",
        "body": "谢谢你的努力，目前的版本看起来还不错，我想这样的话我们的hook的效率会有提升。我晚些时候会再检查和测试一下，如果没问题的话我会着手合并，并且可能会立即做一个commit做一些微小的调整，谢谢！"
      },
      {
        "user": "DerryAlex",
        "created_at": "2024-12-11T12:48:19Z",
        "body": "真的有双缓存区吗？怎么看着只是把锁去掉了，并把 buffer 改成了固定大小\r\n\r\n真实现 ring buffer 的话，也不能完全去掉 lock, 不过只锁 `buffer[read_index]` 应该能降低冲突的概率，还是需要实验来测试一下。\r\n\r\n另外可以对每帧都存一下格式吧，这样也不需要 huge buffer 的 workaround\r\n\r\n "
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T12:51:57Z",
        "body": "> 真的有双缓存区吗？怎么看着只是把锁去掉了，并把 buffer 改成了固定大小\r\n\r\n1. 没有双缓冲区。\r\n2. buffer 改成固定大小（足够大），使得不需要所谓的“重分配”，因此不需要锁来保证 read 过程中 framebuffer 不被“重分配”。同时，这足够大的 buffer 并不会带来令人担忧的内存开销，因为只有真正用到对应虚拟页面，kernel 才会分配物理内存。\r\n\r\n---\r\n\r\n补充：我理解原代码中锁只是为了避免“重分配”使得正读取 buffer 的线程访问无效内存。"
      },
      {
        "user": "DerryAlex",
        "created_at": "2024-12-11T13:12:07Z",
        "body": "> 补充：我理解原代码中锁只是为了避免“重分配”使得正读取 buffer 的线程访问无效内存。\r\n\r\n一部分数据是上一帧的，另外一部分数据是下一帧的也不行吧"
      },
      {
        "user": "Coekjan",
        "created_at": "2024-12-11T13:23:15Z",
        "body": "> 一部分数据是上一帧的，另外一部分数据是下一帧的也不行吧\r\n\r\n如果用目前 PR 的代码，理论上是可能会出现这种情况的。由于我本地测试时，几乎感知不到这种现象，这种现象也许并不那么“错误”，所以还是完全移除了锁。当然，若维护者认为应当极力避免这种竞态，我认为可以考虑改为双缓冲区实现。"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-11T14:01:56Z",
        "body": "我觉得如果测试下来几乎不会有可察觉到的副作用的话，去除锁对于改善效率和功耗应当是有正面作用的。不过既然另一位贡献者有些疑虑，那我就多进行些测试. 不过由于近日仓库突然感觉热度增加了不少，本PR的处理速度可能也要稍微放缓一点（由于我也有本职工作要做），预计可能最晚会到本周末处理，还希望@Coekjan 理解.🥲"
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-14T15:26:53Z",
        "body": "经过测试可以验证至少在um5606wa (HX370) 的性能模式下，hugebuffer的方法可以降低2W的封装功耗(which is huge imho)，但在安静模式下（封装功耗同样大约为4.7W）功耗几乎没有区别. 但我认为这说明我们值得用这个简单的手段完全移除mutex，感谢@Coekjan 的工作！但不过由于我感觉代码中有多处实现需要略微调整，暂时先合入`hugebuffer` branch做进一步修改，随后并入`master`."
      },
      {
        "user": "xuwd1",
        "created_at": "2024-12-14T15:34:35Z",
        "body": "待我修改完毕并将`hugebuffer`合入`master`后，我会对`README.md`进行相应的调整以修正其中的说明并增加相应的credits，谢谢！"
      }
    ],
    "satisfaction_conditions": [
      "A solution that eliminates mutex locks while maintaining memory safety",
      "A performance improvement that reduces power consumption",
      "A solution that prevents memory reallocation issues during framebuffer parameter changes",
      "An implementation that doesn't require excessive physical memory consumption",
      "Information about how to measure power consumption for performance testing"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:00:27"
    }
  },
  {
    "number": 1,
    "title": "关于 OpenCV",
    "created_at": "2024-11-21T08:09:57Z",
    "closed_at": "2024-11-25T19:52:35Z",
    "commit_id": "c3d9465e4777e018e3d797965b7321d77bd9fbf2",
    "labels": [],
    "url": "https://github.com/xuwd1/wemeet-wayland-screenshare/issues/1",
    "body": "你试过用 dlopen（`RTLD_LOCAL`）来加载 opencv 库吗？虽然没看到崩溃细节，但我怀疑是符号冲突，那么 RTLD_LOCAL 应当能避免。",
    "comments_url": "https://api.github.com/repos/xuwd1/wemeet-wayland-screenshare/issues/1/comments",
    "author": "lilydjwg",
    "comments": [
      {
        "user": "xuwd1",
        "created_at": "2024-11-21T08:18:37Z",
        "body": "好主意，感谢建议，我近日会试一下. 之前使用的方法都是在cmake中链接opencv."
      },
      {
        "user": "xuwd1",
        "created_at": "2024-11-25T19:52:35Z",
        "body": "本项目现在已经根据提议实现了对opencv库的动态加载. 得益于此，现在本项目中的图像缩放可以确保aspect ratio正确了，感谢提议！"
      }
    ],
    "satisfaction_conditions": [
      "A solution that resolves symbol conflicts when loading OpenCV libraries",
      "A method that ensures correct aspect ratio in image scaling operations",
      "An alternative approach to the traditional CMake linking method for OpenCV"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-14 01:00:40"
    }
  }
]